# üè• Azure RAG Chat - Chat con Manuales Biom√©dicos

Aplicaci√≥n de chat basada en el patr√≥n **RAG (Retrieval Augmented Generation)** que permite a field engineers consultar informaci√≥n t√©cnica de manuales de dispositivos biom√©dicos usando Azure AI Search y Azure OpenAI.

## üìã Descripci√≥n del Proyecto

Esta aplicaci√≥n est√° dise√±ada para que los **field engineers** puedan hacer preguntas sobre manuales t√©cnicos y de usuario de dispositivos biom√©dicos durante el mantenimiento de equipos. La aplicaci√≥n:

1. **Recibe preguntas** del usuario a trav√©s de una interfaz de chat en Streamlit (texto o voz).
2. **Busca informaci√≥n relevante** en un √≠ndice de Azure AI Search que contiene chunks de manuales biom√©dicos.
3. **Genera respuestas contextualizadas** usando Azure OpenAI con el contexto recuperado.
4. **Reproduce respuestas en voz** (opcional) usando Azure Speech Services para una experiencia hands-free.

## üèóÔ∏è Arquitectura

La aplicaci√≥n utiliza una arquitectura RAG con los siguientes componentes:

- **Frontend**: Streamlit (interfaz de chat interactiva con soporte de voz)
- **Motor de b√∫squeda**: Azure AI Search (√≠ndice con chunks de manuales biom√©dicos)
- **Modelo de lenguaje**: Azure OpenAI (generaci√≥n de respuestas contextualizadas)
- **Servicios de voz**: Azure Speech Services (opcional, para entrada y salida de voz)
- **Patr√≥n**: RAG (Retrieval Augmented Generation)

### Flujo de datos:

```
Usuario ‚Üí Streamlit UI (texto o voz) ‚Üí Azure Speech STT (si es voz)
                                              ‚Üì
                                    Texto de la pregunta
                                              ‚Üì
                                    RAG Pipeline ‚Üí Azure AI Search (b√∫squeda)
                                              ‚Üì
                                    Contexto recuperado
                                              ‚Üì
                                    Azure OpenAI (generaci√≥n)
                                              ‚Üì
                                    Respuesta + Fuentes
                                              ‚Üì
                                    Azure Speech TTS (opcional) ‚Üí Audio
                                              ‚Üì
                                    Usuario (texto + audio)
```

## üîß Requisitos Previos

Antes de ejecutar la aplicaci√≥n, necesitas:

1. **Cuenta de Azure** con acceso a:
   - Azure AI Search (servicio creado)
   - Azure OpenAI (recurso con deployment de modelo de chat, por ejemplo GPT-4 o GPT-3.5-turbo)
   - Azure Speech Services (opcional, solo si quieres usar funcionalidad de voz)

2. **√çndice de Azure AI Search**:
   - Nombre del √≠ndice: **biomed-manuals-demo-index**
   - El √≠ndice debe estar creado y poblado con chunks de manuales biom√©dicos (PDFs procesados)
   - Los manuales deben estar subidos a Azure Blob Storage y procesados mediante un indexer o el wizard de "Import Data" en Azure Portal
   - Campos del √≠ndice que usa la aplicaci√≥n:
     - `content` (String, searchable): Texto de los manuales
     - `metadata_storage_name` (String, filterable, sortable, facetable): Nombre del archivo PDF (mostrado como "source" en la UI)
     - `metadata_storage_path` (String, key): Clave interna del documento

3. **Python 3.x** instalado (recomendado 3.8+)

4. **Variables de entorno** configuradas (ver secci√≥n de configuraci√≥n)

## üì¶ Instalaci√≥n

### 1. Clonar el repositorio

```bash
git clone <url-del-repositorio>
cd azure-rag-chat
```

### 2. Crear y activar entorno virtual

**Windows:**
```bash
python -m venv venv
venv\Scripts\activate
```

**Linux/Mac:**
```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 4. Configurar variables de entorno

Crea un archivo `.env` en la ra√≠z del proyecto bas√°ndote en `.env.example`:

```bash
cp .env.example .env
```

Edita el archivo `.env` y completa con tus credenciales de Azure:

```env
# Azure AI Search Configuration
AZURE_SEARCH_ENDPOINT="https://<tu-servicio-search>.search.windows.net"
AZURE_SEARCH_INDEX="biomed-manuals-demo-index"
AZURE_SEARCH_API_KEY="<tu-api-key-search>"

# Azure OpenAI Configuration
AZURE_OPENAI_ENDPOINT="https://<tu-recurso-openai>.openai.azure.com"
AZURE_OPENAI_API_KEY="<tu-api-key-openai>"
AZURE_OPENAI_DEPLOYMENT="<nombre-del-deployment-del-modelo>"

# Azure Speech Services Configuration (Opcional - para funcionalidad de voz)
# Si no configuras estas variables, la aplicaci√≥n funcionar√° solo con texto
AZURE_SPEECH_API_KEY="<tu-api-key-speech>"
AZURE_SPEECH_REGION="<tu-region-speech>"
AZURE_SPEECH_LANGUAGE="es-ES"
AZURE_SPEECH_VOICE="es-ES-ElviraNeural"

# Streamlit Configuration (opcional)
STREAMLIT_SERVER_PORT="8501"
```

### üìç C√≥mo obtener las credenciales de Azure Speech Services

Si quieres habilitar la funcionalidad de voz, necesitas crear un recurso de **Speech Services** en Azure:

#### 1. Crear el recurso de Speech Services

1. Ve al [Portal de Azure](https://portal.azure.com)
2. Haz clic en **"Crear un recurso"** o **"+ Crear"**
3. Busca **"Speech"** o **"Speech Services"**
4. Selecciona **"Speech"** de Microsoft
5. Haz clic en **"Crear"**
6. Completa el formulario:
   - **Suscripci√≥n**: Selecciona tu suscripci√≥n
   - **Grupo de recursos**: Crea uno nuevo o usa uno existente
   - **Regi√≥n**: Selecciona una regi√≥n cercana (ej: `eastus`, `westeurope`, `southcentralus`)
   - **Nombre**: Elige un nombre √∫nico para tu recurso (ej: `mi-speech-service`)
   - **Plan de tarifa**: Selecciona `Free F0` (para pruebas) o `Standard S0` (para producci√≥n)
7. Haz clic en **"Revisar y crear"** y luego en **"Crear"**

#### 2. Obtener la API Key y la Regi√≥n

Una vez creado el recurso:

1. Ve a tu recurso de Speech Services en el Portal de Azure
2. En el men√∫ lateral, busca la secci√≥n **"Claves y punto de conexi√≥n"** (Keys and Endpoint)
3. Ah√≠ encontrar√°s:
   - **KEY 1** o **KEY 2**: Esta es tu `AZURE_SPEECH_API_KEY`
   - **Ubicaci√≥n/Regi√≥n**: Esta es tu `AZURE_SPEECH_REGION` (ej: `eastus`, `westeurope`)

#### 3. Configurar idioma y voz

- **AZURE_SPEECH_LANGUAGE**: C√≥digo de idioma (ej: `es-ES` para espa√±ol de Espa√±a, `es-MX` para espa√±ol de M√©xico)
- **AZURE_SPEECH_VOICE**: Nombre de la voz neural. Algunas opciones en espa√±ol:
  - `es-ES-ElviraNeural` (femenina, Espa√±a)
  - `es-ES-AlvaroNeural` (masculina, Espa√±a)
  - `es-MX-DaliaNeural` (femenina, M√©xico)
  - `es-MX-JorgeNeural` (masculina, M√©xico)

Puedes ver todas las voces disponibles en: [Documentaci√≥n de voces de Azure](https://learn.microsoft.com/azure/ai-services/speech-service/language-support?tabs=tts)

#### 4. Ejemplo de configuraci√≥n completa

```env
AZURE_SPEECH_API_KEY="a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6"
AZURE_SPEECH_REGION="eastus"
AZURE_SPEECH_LANGUAGE="es-ES"
AZURE_SPEECH_VOICE="es-ES-ElviraNeural"
```

**Nota**: Si no configuras estas variables, la aplicaci√≥n funcionar√° normalmente pero solo con entrada de texto (sin funcionalidad de voz).

## üöÄ Ejecutar la Aplicaci√≥n

Una vez configurado todo, ejecuta:

**Windows (PowerShell):**
```powershell
# Activar el entorno virtual
.\venv2\Scripts\Activate.ps1

# Si tienes problemas con la pol√≠tica de ejecuci√≥n, ejecuta primero:
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser

# Ejecutar la aplicaci√≥n
streamlit run app/main.py
```

**Windows (CMD):**
```cmd
venv2\Scripts\activate
streamlit run app/main.py
```

**Linux/Mac:**
```bash
source venv2/bin/activate
streamlit run app/main.py
```

La aplicaci√≥n se abrir√° autom√°ticamente en tu navegador en `http://localhost:8501`.

## üìÅ Estructura del Proyecto

```
azure-rag-chat/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py                    # Aplicaci√≥n principal de Streamlit
‚îÇ   ‚îú‚îÄ‚îÄ config.py                  # Gesti√≥n de configuraci√≥n y variables de entorno
‚îÇ   ‚îî‚îÄ‚îÄ services/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ azure_search_client.py # Cliente para Azure AI Search
‚îÇ       ‚îú‚îÄ‚îÄ azure_openai_client.py # Cliente para Azure OpenAI
‚îÇ       ‚îú‚îÄ‚îÄ azure_speech_client.py  # Cliente para Azure Speech Services (STT/TTS)
‚îÇ       ‚îî‚îÄ‚îÄ rag_pipeline.py        # Pipeline RAG que orquesta todo
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ search-index-demo.json          # Esquema simplificado de √≠ndice (demo)
‚îÇ   ‚îî‚îÄ‚îÄ search-index-prod-example.json  # Esquema completo para producci√≥n
‚îú‚îÄ‚îÄ .env.example                  # Plantilla de variables de entorno
‚îú‚îÄ‚îÄ requirements.txt              # Dependencias del proyecto
‚îî‚îÄ‚îÄ README.md                     # Este archivo
```

## üìä Esquema del √çndice

### √çndice Real en Azure (`biomed-manuals-demo-index`)

La aplicaci√≥n est√° configurada para trabajar con el √≠ndice **biomed-manuals-demo-index** que debe estar creado en Azure AI Search. Este √≠ndice utiliza el siguiente esquema:

**Campos principales que usa la aplicaci√≥n:**
- `content` (String, searchable, retrievable): Texto extra√≠do de los chunks de los manuales biom√©dicos. Este es el campo principal sobre el que se realiza la b√∫squeda textual.
- `metadata_storage_name` (String, filterable, sortable, facetable, retrievable): Nombre del archivo PDF de origen. La aplicaci√≥n lo mapea internamente como "source" para mostrarlo en la interfaz.
- `metadata_storage_path` (String, key, retrievable): Ruta de almacenamiento del documento. Este campo es la clave (key) del √≠ndice.

**Notas:**
- El √≠ndice no incluye campos como `id`, `source` directo, `pageNumber`, `contentVector` ni configuraci√≥n de b√∫squeda vectorial.
- La aplicaci√≥n realiza b√∫squeda textual est√°ndar sobre el campo `content`.
- Los archivos JSON en `docs/` (`search-index-demo.json` y `search-index-prod-example.json`) fueron dise√±os iniciales de ejemplo, pero la implementaci√≥n actual est√° adaptada al esquema real del √≠ndice creado en Azure Portal.

## üéØ Uso de la Aplicaci√≥n

1. **Abre la aplicaci√≥n** en tu navegador (se abre autom√°ticamente al ejecutar Streamlit).

2. **Ajusta par√°metros** en la barra lateral (opcional):
   - `top_k`: N√∫mero de documentos a recuperar (1-10)
   - `temperature`: Temperatura del modelo (0.0-1.0)

3. **Haz tu pregunta** de dos formas:
   - **Texto**: Escribe tu pregunta en el campo de chat y presiona Enter o haz clic en enviar.
   - **Voz** (si est√° configurado): Haz clic en el bot√≥n de micr√≥fono üéôÔ∏è integrado en el campo de chat, graba tu pregunta y env√≠a.
   
   Ejemplos de preguntas:
   - "¬øC√≥mo calibro el sensor de ox√≠geno del modelo X?"
   - "¬øCu√°l es el procedimiento de mantenimiento preventivo?"
   - "¬øQu√© c√≥digo de error significa E-123?"
   - "¬øC√≥mo cambio el filtro del dispositivo Y?"

4. **Revisa la respuesta** que aparece en tiempo real (streaming) y las fuentes utilizadas (nombre del PDF).

5. **Escucha la respuesta** (si est√° configurado Azure Speech): La respuesta se reproduce autom√°ticamente en audio despu√©s de generarse.

6. **Contin√∫a la conversaci√≥n** haciendo m√°s preguntas (puedes alternar entre texto y voz).

7. **Limpia la conversaci√≥n** usando el bot√≥n en la barra lateral cuando quieras empezar de nuevo.

## üîç Caracter√≠sticas

- ‚úÖ Interfaz de chat intuitiva con Streamlit
- ‚úÖ **Entrada de voz integrada**: Graba preguntas directamente desde el campo de chat
- ‚úÖ **Salida de voz**: Respuestas habladas autom√°ticamente (opcional)
- ‚úÖ B√∫squeda sem√°ntica en manuales biom√©dicos
- ‚úÖ Generaci√≥n de respuestas contextualizadas con streaming en tiempo real
- ‚úÖ Visualizaci√≥n de fuentes (PDF y relevancia)
- ‚úÖ Par√°metros ajustables (top_k, temperature)
- ‚úÖ Manejo de errores robusto
- ‚úÖ Historial de conversaci√≥n completo
- ‚úÖ Flujo unificado: todas las preguntas (texto o voz) aparecen en el mismo chat

## üìù Notas T√©cnicas

- La aplicaci√≥n usa **b√∫squeda por texto** por defecto. El c√≥digo est√° preparado para usar b√∫squeda vectorial si proporcionas embeddings.
- El modelo de Azure OpenAI debe ser un modelo de **chat** (por ejemplo, GPT-4, GPT-3.5-turbo).
- La versi√≥n de la API de Azure OpenAI usada es `2024-02-15-preview` (ajustable en `azure_openai_client.py`).
- Los chunks de los manuales deben estar previamente indexados en Azure AI Search.
- **Azure Speech Services** es opcional. Si no est√° configurado, la aplicaci√≥n funciona solo con texto.
- El widget de chat de Streamlit integra el bot√≥n de micr√≥fono cuando `accept_audio=True`, permitiendo grabar directamente desde el campo de entrada.
- Las respuestas de voz se generan autom√°ticamente despu√©s de cada respuesta del asistente (si Azure Speech est√° configurado).

## ü§ù Contribuciones

Las contribuciones son bienvenidas. Por favor, abre un issue o pull request si tienes sugerencias o mejoras.

## üìÑ Licencia

Este proyecto es una demo educativa.

---

**Desarrollado con ‚ù§Ô∏è para field engineers de dispositivos biom√©dicos**

